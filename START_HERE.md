# START HERE - Visual Guide

## For Non-Technical Users

### Option 1: One-Click Quick Test (Recommended First Time)
```
1. Double-click: QUICK_TEST.bat
2. Watch it run (takes 2-3 minutes)
3. Results auto-export to Google Sheets
4. Done! Check your Sheet for new rows
```

### Option 2: Full Menu (More Control)
```
1. Double-click: RUN_CRAWLER.bat
2. Choose option 1, 2, or 3
3. Wait for crawl to finish
4. Answer Y to export
5. Press Enter for default URL
6. Check Google Sheet
```

---

## What Each File Does

| File | Purpose | Use When |
|------|---------|----------|
| `QUICK_TEST.bat` | Auto crawl (10 URLs) + export | First time / quick test |
| `RUN_CRAWLER.bat` | Menu with 3 crawl options | Full control needed |
| `RUN_CRAWLER_QUICK.md` | How-to guide | Need instructions |
| `INTEGRATION_COMPLETE.md` | Feature summary | Want to know details |
| `IMPLEMENTATION_SUMMARY.md` | Technical summary | For developers |

---

## Your Google Sheet

All crawled data goes here:
```
https://docs.google.com/spreadsheets/d/1-CTG-z5o9XhLbGy-3SZr5bUF9X0rekKLV0Zw-7DX8xI
```

Columns added per URL:
- URL
- Email (if found)
- Contact Form URL
- Company Name
- Industry
- HTTP Status
- Robots Allowed
- Last Crawled At
- Crawl Status
- Error Message

---

## Troubleshooting

### "What if nothing happens?"
â†’ Open terminal and type: `python -c "import requests; print('OK')"`
â†’ Should print `OK` (means Python is working)

### "What if export fails?"
â†’ Check that your Google Sheet is shared with anyone who has the link
â†’ Or contact support with the error message

### "How do I know it worked?"
â†’ Check your Google Sheet
â†’ You should see new rows with the crawled URLs

### "How long does it take?"
â†’ 10 URLs = ~2-3 minutes
â†’ 50 URLs = ~5-10 minutes
â†’ 100+ URLs = longer (depends on page size/network)

---

## Getting Help

1. **Read**: `RUN_CRAWLER_QUICK.md` â€” most common questions answered there
2. **Check**: Google Sheet â€” verify rows were added
3. **Run**: `QUICK_TEST.bat` â€” test with 10 URLs first
4. **Review**: Error messages in terminal window

---

## Quick Facts

âœ“ **No credentials needed** â€” Apps Script URL is embedded  
âœ“ **Automatic export** â€” After crawl, you're asked to export  
âœ“ **Data goes to Google Sheets** â€” All results visible in one place  
âœ“ **Takes 2-3 minutes** â€” Small test crawl (10 URLs)  
âœ“ **Non-technical UI** â€” Just double-click and answer prompts  

---

## Ready?

**ðŸ‘‰ Double-click `QUICK_TEST.bat` to start!**

(Or open `RUN_CRAWLER.bat` if you want to choose crawl size)

